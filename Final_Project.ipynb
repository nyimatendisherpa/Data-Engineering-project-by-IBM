{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "You have been hired as a data engineer by research organization. Your boss has asked you to create a code that can be used to compile the list of the top 10 largest banks in the world ranked by market capitalization in billion USD. Further, the data needs to be transformed and stored in GBP, EUR and INR as well, in accordance with the exchange rate information that has been made available to you as a CSV file. The processed information table is to be saved locally in a CSV format and as a database table.\n",
        "\n",
        "Your job is to create an automated system to generate this information so that the same can be executed in every financial quarter to prepare the report."
      ],
      "metadata": {
        "id": "JvWgp7LH7qDM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tqJG5ZTdxlSs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b90b3c5-66de-4eca-cc17-f26289d9cae3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Collecting bs4\n",
            "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from bs4) (4.13.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->bs4) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->bs4) (4.12.2)\n",
            "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=e5410475f0f00690c3978bfe46dd75c66bc8dff73fc8c08dcad331e6516cadbc\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, bs4\n",
            "Successfully installed bs4-0.0.2 wget-3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy pandas bs4 wget\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sqlite3\n",
        "import requests\n",
        "from datetime import datetime\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "qeU1IXrxCyvu"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logging Process"
      ],
      "metadata": {
        "id": "SPEScMpJEvif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def log_progress(message):\n",
        "  timestamp_format=\"%y-%h_d-%H:%M:%S\"\n",
        "  now=datetime.now()\n",
        "  timestamp=now.strftime(timestamp_format)\n",
        "  with open(log_file,\"a\") as f:\n",
        "    f.write(timestamp+\":\"+message +\"\\n\")"
      ],
      "metadata": {
        "id": "rNWq0GNidRuG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uWvu8jxGd4tx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract(url, table_attribs):\n",
        "    ''' This function aims to extract the required\n",
        "    information from the website and save it to a data frame. The\n",
        "    function returns the data frame for further processing. '''\n",
        "\n",
        "    page = requests.get(url).text\n",
        "    soup = BeautifulSoup(page, \"html.parser\")\n",
        "\n",
        "    df = pd.DataFrame(columns=table_attribs)\n",
        "\n",
        "    tables = soup.find_all(\"tbody\")\n",
        "    rows = tables[0].find_all(\"tr\")\n",
        "\n",
        "    for row in rows:\n",
        "        col = row.find_all(\"td\")\n",
        "        if len(col) != 0:\n",
        "            data_dict = {\"Name\": col[1].find_all(\"a\")[1][\"title\"],\n",
        "                         \"MC_USD_Billion\": float(col[2].contents[0][:-1])}\n",
        "            df1 = pd.DataFrame(data_dict, index=[0])\n",
        "            df = pd.concat([df, df1], ignore_index=True)\n",
        "\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "u2G5dKWxFL2g"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform(df, csv_path):\n",
        "    ''' This function accesses the CSV file for exchange rate\n",
        "    information, and adds three columns to the data frame, each\n",
        "    containing the transformed version of Market Cap column to\n",
        "    respective currencies'''\n",
        "\n",
        "    # Read exchange rate CSV file\n",
        "    exchange_rate = pd.read_csv(csv_path)\n",
        "\n",
        "    # Convert to a dictionary with \"Currency\" as keys and \"Rate\" as values\n",
        "    exchange_rate = exchange_rate.set_index(\"Currency\").to_dict()[\"Rate\"]\n",
        "\n",
        "    # Add MC_GBP_Billion, MC_EUR_Billion, and MC_INR_Billion\n",
        "    # columns to dataframe. Round off to two decimals\n",
        "    df[\"MC_GBP_Billion\"] = [np.round(x * exchange_rate[\"GBP\"], 2) for x in df[\"MC_USD_Billion\"]]\n",
        "    df[\"MC_EUR_Billion\"] = [np.round(x * exchange_rate[\"EUR\"], 2) for x in df[\"MC_USD_Billion\"]]\n",
        "    df[\"MC_INR_Billion\"] = [np.round(x * exchange_rate[\"INR\"], 2) for x in df[\"MC_USD_Billion\"]]\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "inRi3lEaHWXm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_to_csv(df, output_path):\n",
        "    ''' This function saves the final data frame as a CSV file in\n",
        "    the provided path. Function returns nothing.'''\n",
        "\n",
        "    df.to_csv(output_path)"
      ],
      "metadata": {
        "id": "oiFHW3EyH28S"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading to Database"
      ],
      "metadata": {
        "id": "NMTCuN61IBbb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_to_db(df, sql_connection, table_name):\n",
        "    ''' This function saves the final data frame to a database\n",
        "    table with the provided name. Function returns nothing.'''\n",
        "\n",
        "    df.to_sql(table_name, sql_connection, if_exists='replace', index=False)"
      ],
      "metadata": {
        "id": "lNn7p8m3H_0u"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to run querries on database"
      ],
      "metadata": {
        "id": "iBjJZjdzIIF_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_query(query_statement, sql_connection):\n",
        "    ''' This function runs the query on the database table and\n",
        "    prints the output on the terminal. Function returns nothing. '''\n",
        "\n",
        "    print(query_statement)\n",
        "    query_output = pd.read_sql(query_statement, sql_connection)\n",
        "    print(query_output)"
      ],
      "metadata": {
        "id": "xshOI1F2IGdU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running ETl Process"
      ],
      "metadata": {
        "id": "GfyXErqjIr6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://web.archive.org/web/20230908091635/https://en.wikipedia.org/wiki/List_of_largest_banks\"\n",
        "csv_path = \"./exchange_rate.csv\"\n",
        "table_attribs = [\"Name\", \"MC_USD_Billion\"]\n",
        "output_path = \"./Largest_banks_data.csv\"\n",
        "db_name = \"Banks.db\"\n",
        "table_name = \"Largest_banks\"\n",
        "log_file = \"./code_log.txt\"\n",
        "\n",
        "log_progress(\"Preliminaries complete. Initiating ETL process\")"
      ],
      "metadata": {
        "id": "39HDMed5Iq2t"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "calling extract function"
      ],
      "metadata": {
        "id": "u-KU7TuVI7Yi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = extract(url, table_attribs)\n",
        "print(df)\n",
        "\n",
        "log_progress(\"Data extraction complete. Initiating Transformation process\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LToNNlJIzBx",
        "outputId": "66dbe746-c163-4c1a-d5bf-51c95ae295d4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                      Name  MC_USD_Billion\n",
            "0                           JPMorgan Chase          432.92\n",
            "1                          Bank of America          231.52\n",
            "2  Industrial and Commercial Bank of China          194.56\n",
            "3               Agricultural Bank of China          160.68\n",
            "4                                HDFC Bank          157.91\n",
            "5                              Wells Fargo          155.87\n",
            "6                                     HSBC          148.90\n",
            "7                           Morgan Stanley          140.83\n",
            "8                  China Construction Bank          139.82\n",
            "9                            Bank of China          136.81\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-9395c0be0ee4>:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df = pd.concat([df, df1], ignore_index=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = transform(df, csv_path)\n",
        "print(df)\n",
        "\n",
        "log_progress(\"Data transformation complete. Initiating Loading process\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUMRe6syI-2_",
        "outputId": "11c47c92-e99c-48a8-8c7b-c3d71708ac30"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                      Name  MC_USD_Billion  MC_GBP_Billion  \\\n",
            "0                           JPMorgan Chase          432.92          346.34   \n",
            "1                          Bank of America          231.52          185.22   \n",
            "2  Industrial and Commercial Bank of China          194.56          155.65   \n",
            "3               Agricultural Bank of China          160.68          128.54   \n",
            "4                                HDFC Bank          157.91          126.33   \n",
            "5                              Wells Fargo          155.87          124.70   \n",
            "6                                     HSBC          148.90          119.12   \n",
            "7                           Morgan Stanley          140.83          112.66   \n",
            "8                  China Construction Bank          139.82          111.86   \n",
            "9                            Bank of China          136.81          109.45   \n",
            "\n",
            "   MC_EUR_Billion  MC_INR_Billion  \n",
            "0          402.62        35910.71  \n",
            "1          215.31        19204.58  \n",
            "2          180.94        16138.75  \n",
            "3          149.43        13328.41  \n",
            "4          146.86        13098.63  \n",
            "5          144.96        12929.42  \n",
            "6          138.48        12351.26  \n",
            "7          130.97        11681.85  \n",
            "8          130.03        11598.07  \n",
            "9          127.23        11348.39  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "calling load function"
      ],
      "metadata": {
        "id": "uM9_xpP3JHMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "load_to_csv(df, output_path)\n",
        "log_progress(\"Data saved to CSV file\")"
      ],
      "metadata": {
        "id": "oGgBedfGJCGp"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initiate SQLite3 connection\n",
        "\n"
      ],
      "metadata": {
        "id": "yQvYlcw3JNRw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sql_connection = sqlite3.connect(db_name)\n",
        "\n",
        "log_progress(\"SQL Connection initiated\")\n"
      ],
      "metadata": {
        "id": "hcDelUoGJF4h"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load to DataBase"
      ],
      "metadata": {
        "id": "7jfpxISrJSF4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "load_to_db(df, sql_connection, table_name)\n",
        "\n",
        "log_progress(\"Data loaded to Database as a table, Executing queries\")"
      ],
      "metadata": {
        "id": "mjMJETlAJP9N"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run querry\n",
        "\n",
        "\n",
        "1.  print the content of the entre table\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0PfwiAb8JcbU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_statement = f\"SELECT * from {table_name}\"\n",
        "run_query(query_statement, sql_connection)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oywXyJ4eJZoV",
        "outputId": "512c2f56-e84e-4836-e378-4eaf4203cdc8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SELECT * from Largest_banks\n",
            "                                      Name  MC_USD_Billion  MC_GBP_Billion  \\\n",
            "0                           JPMorgan Chase          432.92          346.34   \n",
            "1                          Bank of America          231.52          185.22   \n",
            "2  Industrial and Commercial Bank of China          194.56          155.65   \n",
            "3               Agricultural Bank of China          160.68          128.54   \n",
            "4                                HDFC Bank          157.91          126.33   \n",
            "5                              Wells Fargo          155.87          124.70   \n",
            "6                                     HSBC          148.90          119.12   \n",
            "7                           Morgan Stanley          140.83          112.66   \n",
            "8                  China Construction Bank          139.82          111.86   \n",
            "9                            Bank of China          136.81          109.45   \n",
            "\n",
            "   MC_EUR_Billion  MC_INR_Billion  \n",
            "0          402.62        35910.71  \n",
            "1          215.31        19204.58  \n",
            "2          180.94        16138.75  \n",
            "3          149.43        13328.41  \n",
            "4          146.86        13098.63  \n",
            "5          144.96        12929.42  \n",
            "6          138.48        12351.26  \n",
            "7          130.97        11681.85  \n",
            "8          130.03        11598.07  \n",
            "9          127.23        11348.39  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Printing average market capitalization of all  banks in billion GBP"
      ],
      "metadata": {
        "id": "7hxfKREgJs8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_statement = f\"SELECT AVG(MC_GBP_Billion) FROM {table_name}\"\n",
        "run_query(query_statement, sql_connection)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCtYopvQJpa2",
        "outputId": "cd891350-a650-441b-a933-93426ce4bb8c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SELECT AVG(MC_GBP_Billion) FROM Largest_banks\n",
            "   AVG(MC_GBP_Billion)\n",
            "0              151.987\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print the name of the top bank"
      ],
      "metadata": {
        "id": "cEKPsqdtJ50F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_statement = f\"SELECT Name from {table_name} LIMIT 5\"\n",
        "run_query(query_statement, sql_connection)\n",
        "\n",
        "log_progress(\"Process Complete\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTpfLBkdJ3Cf",
        "outputId": "ae6e7384-7331-46e7-a0f8-cf5b49e9a9d4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SELECT Name from Largest_banks LIMIT 5\n",
            "                                      Name\n",
            "0                           JPMorgan Chase\n",
            "1                          Bank of America\n",
            "2  Industrial and Commercial Bank of China\n",
            "3               Agricultural Bank of China\n",
            "4                                HDFC Bank\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SQL 3 connection close"
      ],
      "metadata": {
        "id": "FhTXmKfgKDba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sql_connection.close()\n",
        "\n",
        "log_progress(\"Server Connection closed\")"
      ],
      "metadata": {
        "id": "EK_uKCcGJ_SP"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verify Log entries\n",
        "upon successful completion of executation ,see the relevent entries made in the log file in relation to the stages of code executation."
      ],
      "metadata": {
        "id": "xSLgPiTNKMpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(log_file, \"r\") as log:\n",
        "    LogContent = log.read()\n",
        "    print(LogContent)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFXDB9o3KK5B",
        "outputId": "60b9cde6-5d5e-4781-a768-3b976f092ce9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25-Mar_d-08:43:02:Preliminaries complete. Initiating ETL process\n",
            "25-Mar_d-08:43:07:Data extraction complete. Initiating Transformation process\n",
            "25-Mar_d-08:43:10:Data transformation complete. Initiating Loading process\n",
            "25-Mar_d-08:43:13:Data saved to CSV file\n",
            "25-Mar_d-08:43:14:SQL Connection initiated\n",
            "25-Mar_d-08:43:16:Data loaded to Database as a table, Executing queries\n",
            "25-Mar_d-08:43:22:Process Complete\n",
            "25-Mar_d-08:43:23:Server Connection closed\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TPKOv5SlKePN"
      },
      "execution_count": 21,
      "outputs": []
    }
  ]
}